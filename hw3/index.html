<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
	<head>
		<style>
			body {
			    background-color: #eae1f5;
			    padding: 100px;
			    width: 1000px;
			    margin: auto;
			    text-align: left;
			    font-weight: 300;
			    font-family: 'Nunito', sans-serif;
			    color: #121212;
			  }
			  h1, h2, h3, h4 {
			    font-family: 'Nunito', sans-serif;
			  }
			  table {
			    width: 100%;
			    border-collapse: collapse;
			  }
			  th, td {
			    border: 1px solid black;
			    padding: 8px;
			    text-align: left;
			  }
			  th {
			    background-color: #ECF8F7;
			  }
		</style>
		<title>CS 184 Project 3: Pathtracer</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<link href=https://fonts.googleapis.com/css?family=Nunito rel="stylesheet">

		<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	</head>
	<body>
		<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2024</h1>
		<h1 align="middle">Project 3: Pathtracer</h1>
		<h2 align="middle">Christy Quang, Anya Agarwal</h2>
	</body>

	<div>
		<h2 align="middle">Overview</h2>
		<hr>
			<p>
				Site: <a href="https://cal-cs184-student.github.io/hw-webpages-sp24-christyquang/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-sp24-christyquang/hw3/index.html</a>
			</p>
		
		<hr>

		<h2 align="middle">Part 1: Ray Generation and Scene Intersection</h2>
			
		<h3 align="middle">Task 1: Generating Camera Rays</h3>
		<hr>
			<p>
				When generating camera rays, we need to transform the image coordinates <code>(x, y)</code> to camera space by interpolation. In the camera space, the camera is positioned at <code>(0, 0, 0)</code> and looks along its <code>-Z</code> axis. There is an axis-aligned rectangular virtual camera sensor that lies on the <code>Z = -1</code> plane which is why we need to use <code>hFov</code> and <code>vFov</code> field of view angles along the `<code>X</code> and <code>Y</code> axis to transform into camera space. For normalized image coordinates, <code>(0, 0)</code> is the camera origin so we needed to first shift the normalized <code>x</code> and <code>y</code> coordinates to align the <code>Z</code> axis and rescale the normalized coordinates. 
			</p>

			<p>
				Now, in 3-dimensional camera coordinations, we have the vector <code>direction</code> containing <code>x</code>, <code>y</code>, and <code>-1</code>. This is the ray direction vector which is used to transform the camera space ray to world space using the camera-to-world rotation matrix, <code></code>c2w (a 4x4 homogeneous coordinate system transform matrix). Afterwards, we need to normalize <code>d</code>. For the defined ray, the camera is placed at <code>pos</code> (camera position in world space) which is utilized as column 4 and to set the range for the clipping planes, we initialized <code>min_t</code> and <code>max_t</code> of the <code>Ray</code> with <code>nclip</code> and <code>fclip</code> respectively.
			</p>
		<hr>

		<h3 align="middle">Task 2: Generating Pixel Samples</h3>
		<hr>
			<p>
				After creating the camera rays in world space, we generate pixel samples by first generating <code>ns_aa</code> random samples within the pixel. While iterating through all of the pixel samples, we obtain a random sample and normalize the coordinates. Then, we call <code>camera->generate_ray</code>, passing in the normalized <code>(x, y)</code> coordinates, and then call <code>est_radiance_global_illumination</code> to estimate the radiance. After all the samples are processed, we averaged out the pixel color with <code>vec_sum = vec_sum/num_samples</code> and update the <code>sampleBuffer</code> by calling <code>update_pixel</code> with that color.
			</p>
		<hr>

		<h3 align="middle">Task 3: Ray-Triangle Intersection</h3>
		<hr>
			<p>
				To implement ray-triangle intersection, we used Möller-Trumbore intersection algorithm derived from lecture. The <code>Triangle::has_intersection</code> method allows us to test whether there is an intersection between a triangle and the input ray. The bulk of this algorithm lies within the intersection algorithm used where these parameters are computed using the Möller–Trumbore algorithm and determine if and where the ray intersects with the plane of the triangle, and then checks if the intersection point lies within the triangle itself.
			</p>

			<ul>
				<li>
					<code>test_vec.x</code> contains the parameter <code>t</code> of the ray equation where the intersection occurs
				</li>
				<li>
					<code>test_vec.y</code> contains the parameter <code>b1</code>, which represents the barycentric coordinate of the intersection point with respect to the triangle's vertices
				</li>
				<li>
					<code>test_vec.z</code> contains the parameter <code>b2</code>, another barycentric coordinate
				</li>
			</ul>

			<p>
				Intersection Testing:
			</p>

			<ul>
				<li>
					If any of the barycentric coordinates <code>(b1, b2)</code> are less than <code>0</code> or their sum is greater than <code>1</code>, it means the intersection point lies outside the triangle so the function returns false
				</li>
				<li>
					If the parameter <code>t</code> is outside the valid range <code>[r.min_t, r.max_t]</code>, the intersection point is not within the segment of the ray being considered so the function returns false
				</li>
				<li>
					Otherwise, <code>r.max_t</code> is updated to <code>t</code> to limit the maximum intersection distance of the ray and returns true, indicating an intersection has been found
				</li>
			</ul>

			<p>
				If an intersection is found, the function updates the intersection data (<code>isect</code>) with relevant information:
			</p>

			<ul>
				<li>
					<code>t</code>: the parameter <code>t</code> of the ray equation where the intersection occurs
				</li>
				<li>
					<code>n</code>: the surface normal at the intersection point calculated as the weighted sum of the triangle's vertex normals (<code>n1</code>, <code>n2</code>, <code>n3</code>) based on the barycentric coordinates
				</li>
				<li>
					<code>primitive</code>: a pointer to the triangle primitive that was intersected
				</li>
				<li>
					<code>bsdf</code>: a pointer to the surface material (<code>BSDF</code>) at the hit point
				</li>
			</ul>

			<p>
				Essentially, we combine Barycentric coordinates and an implicit definition of a plane to determine whether the intersection point resides inside a triangle primitive. 
			</p>

			<div style="text-align: center;">
				<img src="images/1.3.png" width="750px" />
				<p>Screenshot of <code>CBempty.dae</code></p>
			</div>
		<hr>

		<h3 align="middle">Task 4: Ray-Sphere Intersection</h3>
		<hr>
			<p>
				Ray-sphere intersection was similar since it incorporates the Möller-Trumbore intersection algorithm but a bit more involved than ray-triangle intersection. There is a new <code>test</code> method which returns true if there are intersections and writes the smaller of the two intersection times in <code>t1</code> and the larger in <code>t2</code>. Within these methods, we reduce the intersection points to the roots of a quadratic equation and the discriminant is used to determine the number of intersections. 
			</p>

			<ul>
				<li>
					<code>a</code>: represents the squared magnitude of the ray direction (<code>r.d</code>)
				</li>
				<li>
					<code>b</code>: represents the dot product between the ray direction and the vector from the ray origin to the sphere center
				</li>
				<li>
					<code>c</code>: represents the squared magnitude of the vector from the ray origin to the sphere center minus the squared radius of the sphere
				</li>
				<li>
					<code>t_plus</code>, <code>t_minus</code>: variables to store the potential intersection times calculated using the quadratic formula
				</li>
			</ul>

			<p>
				As such, if <code>discriminant</code> is less than <code>0</code>, this means that the ray missed the sphere/doesn't intersection so we return false. If <code>discriminant</code> is non-negative, this indicates that there is at least one real root so we used the quadratic formula to determine the time of intersection and assign <code>t_plus</code> and <code>t_minus</code>. The function compares <code>t_plus</code> and <code>t_minus</code> to determine which one is smaller and larger in order to assign the smaller intersection time to <code>t1</code> and the larger one to <code>t2</code>.
			</p>

			<p>
				If an intersection is found within the valid range <code>[r.min_t, r.max_t]</code> and <code>t1</code> is adequately updated using the <code>test</code> helper method, <code>has_intersection</code> updates <code>r.max_t</code> to the intersection time <code>t1</code> (the smaller of the two intersection times) and returns true. In <code>intersection</code>, we do the same in addition to populating <code>i</code> (<code>Intersection</code> object) as stated in the spec (<code>t</code>, <code>primitive</code>, <code>bsdf</code>) and the surface normal.
			</p>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/1.4.png" width="100%" />
					<p>
						<code>CBspheres_lambertian.dae</code> 1.4
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/bench-normal-shading.png" width="100%" />
					<p>
						bench normal shading 1.4
					</p>
				 </div>
			</div>

			<br><br>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/cbdragon-normal-shading.png" width="100%" />
					<p>
						cbdragon normal shading 1.4
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/coil-normal-shading.png" width="100%" />
					<p>
						coil normal shading 1.4
					</p>
				 </div>
			</div>
		<hr>

		<h2 align="middle">Part 2: Bounding Volume Hierarchy</h2>
			
		<h3 align="middle">Task 1: Constructing the BVH</h3>
		<hr>
			<p>
				In <code>BVHAccel::construct_bvh</code>, we first generate the outermost bounding box that encloses all the primitives in the given range (<code>start</code> to <code>end</code>). We iterate through all the primitives passed in the range and expand the bounding box to include each primitive's bounding box. 
			</p>

			<p>
				We create a new BVHNode if the number of primitives (<code>num_prim</code>) is less than or equal to the <code>max_leaf_size</code> and initialize its start and end to be the start and end of the primitives.
			</p>

			<p>
				If not, we need to recurse and determine the split point and axis selection to split up the bounding volume hierarchy. First, we computed the average centroid across all the primitives' bounding boxes within the node. This centroid is used to determine the split axis for partitioning the primitives. The split axis is chosen as the axis that results in the smallest bounding box heuristic among the three axes (<code>X</code>, <code>Y</code>, <code>Z</code>). The bounding box heuristic is calculated based on the surface area of the child bounding boxes after splitting and the primitives are partitioned into left and right child nodes based on the chosen split axis and the average centroid.
			</p>

			<p>
				We chose to use the mean position as the split point instead of the median because we would have to sort the primitives along each axis first. Adding the sort step in the recursion increases the time for generating the BVH. Additionally, a general ray-tracer should work well without prior information about the 3D distribution of primitives so we can assume that for an arbitrary scene, the probability of finding a primitive at any point 3D space follows a uniform distribution so the mean centroild location and median centroid location across the axes are approximately equal.
			</p>

			<p>
				<code>left_primitives</code> and <code>right_primitives</code> are used to store primitives on the left and right sides of the split axis which are then redistributed into the left and right vectors based on their centroid positions along the split axis. Within the loop, if the index <code>i</code> is less than the size of the <code>left_primitives</code> vector, it means there are still primitives left to be assigned to the left child node. If <code>i</code> exceeds the size of the <code>left_primitives</code> vector, it means all left primitives have been assigned, and the remaining primitives need to be assigned to the right child node. 
			</p>

			<p>
				Recursive calls to <code>construct_bvh</code> are made to construct the left and right child nodes. For the left child node, the range of primitives is from <code>start</code> to the iterator <code>center_left</code> and for the right child node, the range is from <code>center_left</code> to <code>end</code>.
			</p>

			<p>
				The images below show how utilizing a 3-axis heuristic is better than splitting along only the mean x-coordinate. The bounding boxes encapsulate the primitives more tightly which reduces the probability that a ray hits the bounding box of a BVH without hitting a primitive.
			</p>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/2.1-base-rendering.png" width="100%" />
					<p>
						<code>2.1-base-rendering.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/2.1-desc-1.png" width="100%" />
					<p>
						<code>2.1-desc-1.png</code>
					</p>
				 </div>
			</div>

			<br><br>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/2.1-desc-2.png" width="100%" />
					<p>
						<code>2.1-desc-2.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/2.1-desc-3.png" width="100%" />
					<p>
						<code>2.1-desc-3.png</code>
					</p>
				 </div>
			</div>
		<hr>

		<h3 align="middle">Task 2: Intersecting the Bounding Box</h3>
		<hr>
			<p>
				Implementing <code>BBox::intersect</code> utilizes the given ray and axis-aligned plane intersection and ray and axis-aligned box intersection equations to check whether a ray intersects a given bounding box.
			</p>

			<p>
				Time is represented as $$t = \frac{{p_x' - o_x}}{{d_x}}$$ when perpendicular to the x axis. Intersection times (<code>t</code>) are calculated for each axis using the parametric equation of a ray, where $t = \frac{{p[axis] - o[axis]}}{{d[axis}}$. This equation represents the intersection of the ray with each of the bounding box's six planes along the <code>X</code>, <code>Y</code>, and <code>Z</code> axes. The minimum and maximum intersection times (<code>min_t</code> and <code>max_t</code>) are calculated for each axis which represent the entry and exit points of the ray into and out of the bounding box along each axis. Specifically, the interval of intersection is determined by taking the maximum of the minimum intersection times (<code>min_t</code>) across all axes and the minimum of the maximum intersection times (<code>max_t</code>) across all axes, ensuring that the intersection interval is as tight as possible.
			</p>

			<p>
				If the max of <code>min_t</code> is greater than the min of <code>max_t</code>, it indicates that the ray misses the bounding box along at least one axis which is why we return false (no intersection). Otherwise, <code>t0</code> and <code>t1</code> are updated directly if an intersection is found within the provided range and we return true. 
			</p>
		<hr>

		<h3 align="middle">Task 3: Intersecting the BVH</h3>
		<hr>
			<p>
				The following times were collected by calling <code>./pathtracer -t 8 -r 800 600 -f {filename}.png ../dae/{path to file}.dae</code> with and without BVH acceleration.
			</p>

			<table>
				  <tr>
					    <th>File</th>
					    <th>Without BVH Acceleration</th>
					    <th>With BVH Acceleration</th>
				  </tr>
				  <tr>
					    <td><code>../dae/sky/dragon.dae</code></td>
					    <td>114.1280 seconds</td>
					    <td>0.027 seconds</td>
				  </tr>
				  <tr>
					    <td><code>../dae/sky/CBbunny.dae</code></td>
					    <td>31.9542 seconds</td>
					    <td>0.0211 seconds</td>
				  </tr>
				  <tr>
					    <td><code>../dae/sky/CBlucy.dae</code></td>
					    <td>50.7390 seconds</td>
					    <td>0.0490 seconds</td>
				  </tr>
				  <tr>
					    <td><code>../dae/meshedit/maxplanck.dae</code></td>
					    <td>144.7978 seconds</td>
					    <td>0.0375 seconds</td>
				  </tr>
			</table>

			<br><br>

			<table>
				  <tr>
					    <th>File</th>
					    <th>Intersection Tests Per Ray (Without BVH)</th>
					    <th>Intersection Tests Per Ray (With BVH)</th>
				  </tr>
				  <tr>
					    <td><code>../dae/sky/dragon.dae</code></td>
					    <td>26331.172812 tests per ray</td>
					    <td>13.020385 tests per ray</td>
				  </tr>
				  <tr>
					    <td><code>../dae/sky/CBbunny.dae</code></td>
					    <td>5180.986541 tests per ray</td>
					    <td>14.620026 tests per ray</td>
				  </tr>
				  <tr>
					    <td><code>../dae/sky/CBlucy.dae</code></td>
					    <td>67920.405738 tests per ray</td>
					    <td>10.578069 tests per ray</td>
				  </tr>
				  <tr>
					    <td><code>../dae/meshedit/maxplanck.dae</code></td>
					    <td>9767.330203 tests per ray</td>
					    <td>13.643585 tests per ray</td>
				  </tr>
			</table>

			<p>
				With BVH acceleration, the computational efficiency is significant. For example, the <code>../dae/sky/dragon.dae</code> rendering completed after 0.027 seconds with BVH acceleration while it took 114.1280 seconds without BVH acceleration. Resepectively, there were 26.331.172812 intersection tests per ray without BVH acceleration and 13.020385 intersection tests per ray with BVH aceleration showcasing how without using BVH acceleration, the average number of intersection tests per ray is <code>O(n)</code> and with BVH acceleration is <code>O(log n)</code> where <code>n</code> is the number of primitives in the scene.
			</p>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/maxplanck-2.3.png" width="100%" />
					<p>
						<code>maxplanck-2.3.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/cbbunny.dae-2.3.png" width="100%" />
					<p>
						<code>cbbunny.dae-2.3.png</code>
					</p>
				 </div>
			</div>

			<br><br>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/cblucy.dae-2.3.png" width="100%" />
					<p>
						<code>cblucy.dae-2.3.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/dragon.dae-2.3.png" width="100%" />
					<p>
						<code>dragon.dae-2.3.png</code>
					</p>
				 </div>
			</div>
		<hr>

		<h2 align="middle">Part 3: Direct Illumination</h2>
			
		<h3 align="middle">Task 1: Diffuse BSDF</h3>
		<hr>
			<p>
				<code>DiffuseBSDF::f</code> represents a diffuse material that reflects incoming light equally in all directions on the hemisphere. Originally, we returned the <code>reflectance</code> of the <code>DiffuseBSDF</code> but this didn't match the image in spec. The surface area of a unit hemisphere is <code>2 * PI</code> and based off of lecture slides, the integral of cosine over hemisphere is only <code>1/2</code> the area of the hemisphere, thus why we chose to divide <code>reflectance</code> by <code>PI</code> and resulted in the correct matching image.
			</p>
		<hr>

		<h3 align="middle">Task 2: Zero-bounce Illumination</h3>
		<p>
			To implement zero-bounce illumination, we obtained the <code>Intersection</code> object's <code>bsdf</code> attribute and called <code>get_emission()</code> to get the emission value of the surface material (light that results from zero bounces of light). Afterwards, we updated <code>est_radiance_global_illumination</code> to utilize this method and generate the following image when running <code>./pathtracer -t 8 -s 16 -l 8 -m 6 -H -f CBbunny_16_8.png -r 480 360 ../dae/sky/CBbunny.dae</code>.
		</p>
		
		<hr>
			<div style="text-align: center;">
				<img src="images/3.2-cornell-box.png" width="750px" />
				<p>Screenshot of <code>CBbunny.dae</code> with zero-bounce illumination</p>
			</div>
		<hr>

		<h3 align="middle">Task 3: Direct Lighting with Uniform Hemisphere Shading</h3>
		<hr>
			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/CBbunny_H_16_8-3.3.png" width="100%" />
					<p>
						<code>CBbunny_H_16_8-3.3.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/CBbunny_H_64_32-3.3.png" width="100%" />
					<p>
						<code>CBbunny_H_64_32-3.3.png</code>
					</p>
				 </div>
			</div>

			<br><br>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/CBbunny-sample1.png" width="100%" />
					<p>
						<code>CBbunny-sample1.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/CBbunny-sample4.png" width="100%" />
					<p>
						<code>CBbunny-sample4.png</code>
					</p>
				 </div>
			</div>

			<br><br>

			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/CBbunny-sample16.png" width="100%" />
					<p>
						<code>CBbunny-sample16.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/CBbunny-sample64.png" width="100%" />
					<p>
						<code>CBbunny-sample64.png</code>
					</p>
				 </div>
			</div>
		<hr>

		<h3 align="middle">Task 4: Direct Lighting by Importance Sampling Lights</h3>
		<hr>
			<div style="display: flex; justify-content: space-between;">
					
				<div style="flex: 1; margin-right: 10px; text-align: center;">
					<img src="images/bunny_1_1-3.4.png" width="100%" />
					<p>
						<code>bunny_1_1-3.4.png</code>
					</p>
				</div>
				<div style="flex: 1; margin-left: 10px; text-align: center;">
					<img src="images/bunny_64_32-3.4.png" width="100%" />
					<p>
						<code>bunny_64_32-3.4.png</code>
					</p>
				 </div>
			</div>
		<hr>

		<h2 align="middle">Part 4: Global Illumination</h2>
			
		<h3 align="middle">Task 1: Sampling with Diffuse BSDF</h3>
		<hr>
		<hr>

		<h3 align="middle">Task 2: Global Illumination with up to N Bounces of Light</h3>
		<hr>
		<hr>

		<h3 align="middle">Task 3: Global Illumination with Russian Roulette</h3>
		<hr>
		<hr>

		<h2 align="middle">Part 5: Adaptive Sampling</h2>
		<hr>
		<hr>
	

	</div>
</html>
